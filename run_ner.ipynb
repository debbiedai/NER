{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"run_ner.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPFUisIf7QhtzkwyaKmTaZT"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T_869GAmVqAu","executionInfo":{"status":"ok","timestamp":1637575071505,"user_tz":-480,"elapsed":1752,"user":{"displayName":"戴勤","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03940531057500885788"}},"outputId":"f8a6e10e-ad80-4be3-fe92-899bbdb9e394"},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XdtQjmUPzX2I","executionInfo":{"status":"ok","timestamp":1637575071507,"user_tz":-480,"elapsed":10,"user":{"displayName":"戴勤","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03940531057500885788"}},"outputId":"a680cb6e-3337-4f53-fe3c-9b82fd2b6063"},"source":["%cd \"/content/drive/My Drive/biobert/named-entity-recognition\""],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/biobert/named-entity-recognition\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AGJJsj2kyCI4","executionInfo":{"status":"ok","timestamp":1637575094572,"user_tz":-480,"elapsed":23073,"user":{"displayName":"戴勤","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03940531057500885788"}},"outputId":"5b75db6b-929f-4744-a605-12f950b1ddf4"},"source":["!pip install import-ipynb\n","!pip install seqeval\n","!pip install transformers\n","import import_ipynb\n","\n","from utils_ner import NerDataset, Split, get_labels"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: import-ipynb in /usr/local/lib/python3.7/dist-packages (0.1.3)\n","Requirement already satisfied: seqeval in /usr/local/lib/python3.7/dist-packages (1.2.2)\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.19.5)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.0.1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.1.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.0.0)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.12.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.1.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n"]}]},{"cell_type":"code","metadata":{"id":"3N2PF6TadpBY","executionInfo":{"status":"ok","timestamp":1637575095040,"user_tz":-480,"elapsed":478,"user":{"displayName":"戴勤","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03940531057500885788"}}},"source":["import logging\n","import os\n","import sys\n","import pdb\n","import subprocess\n","\n","from dataclasses import dataclass, field\n","from typing import Dict, List, Optional, Tuple\n","\n","import numpy as np\n","from seqeval.metrics import f1_score, precision_score, recall_score\n","from torch import nn\n","\n","from transformers import (\n","    AutoConfig,\n","    AutoModelForTokenClassification,\n","    AutoModel,\n","    AutoTokenizer,\n","    EvalPrediction,\n","    HfArgumentParser,\n","    Trainer,\n","    TrainingArguments,\n","    set_seed,\n",")\n","from utils_ner import NerDataset, Split, get_labels\n","\n","logger = logging.getLogger(__name__)\n","\n","\n","@dataclass\n","class ModelArguments:\n","    \"\"\"\n","    Arguments pertaining to which model/config/tokenizer we are going to fine-tune from.\n","    \"\"\"\n","\n","    model_name_or_path: str = field(\n","        metadata={\"help\": \"Path to pretrained model or model identifier from huggingface.co/models\"}\n","    )\n","    config_name: Optional[str] = field(\n","        default=None, metadata={\"help\": \"Pretrained config name or path if not the same as model_name\"}\n","    )\n","    tokenizer_name: Optional[str] = field(\n","        default=None, metadata={\"help\": \"Pretrained tokenizer name or path if not the same as model_name\"}\n","    )\n","    use_fast: bool = field(default=False, metadata={\"help\": \"Set this flag to use fast tokenization.\"})\n","    # If you want to tweak more attributes on your tokenizer, you should do it in a distinct script,\n","    # or just modify its tokenizer_config.json.\n","    cache_dir: Optional[str] = field(\n","        default=None, metadata={\"help\": \"Where do you want to store the pretrained models downloaded from s3\"}\n","    )\n","\n","\n","@dataclass\n","class DataTrainingArguments:\n","    \"\"\"\n","    Arguments pertaining to what data we are going to input our model for training and eval.\n","    \"\"\"\n","\n","    data_dir: str = field(\n","        metadata={\"help\": \"The input data dir. Should contain the .txt files for a CoNLL-2003-formatted task.\"}\n","    )\n","    labels: Optional[str] = field(\n","        default=None,\n","        metadata={\"help\": \"Path to a file containing all labels. If not specified, CoNLL-2003 labels are used.\"},\n","    )\n","    max_seq_length: int = field(\n","        default=128,\n","        metadata={\n","            \"help\": \"The maximum total input sequence length after tokenization. Sequences longer \"\n","            \"than this will be truncated, sequences shorter will be padded.\"\n","        },\n","    )\n","    overwrite_cache: bool = field(\n","        default=False, metadata={\"help\": \"Overwrite the cached training and evaluation sets\"}\n","    )\n","\n"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"DqIQWjapd6CJ","executionInfo":{"status":"ok","timestamp":1637575440690,"user_tz":-480,"elapsed":345654,"user":{"displayName":"戴勤","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03940531057500885788"}},"outputId":"1fc71980-7671-4563-8933-fcc38d9d753a"},"source":["def main():\n","    # See all possible arguments in src/transformers/training_args.py\n","    # or by passing the --help flag to this script.\n","    # We now keep distinct sets of args, for a cleaner separation of concerns.\n","    parser = HfArgumentParser((ModelArguments, DataTrainingArguments, TrainingArguments))\n","    model_args, data_args, training_args = parser.parse_json_file(json_file='/content/drive/My Drive/biobert/named-entity-recognition/args.json')\n","    # parser = HfArgumentParser((ModelArguments, DataTrainingArguments, TrainingArguments))\n","    # if len(sys.argv) == 2 and sys.argv[1].endswith(\".json\"):\n","    #     # If we pass only one argument to the script and it's the path to a json file,\n","    #     # let's parse it to get our arguments.\n","    #     model_args, data_args, training_args = parser.parse_json_file(json_file=os.path.abspath(sys.argv[1]))\n","    # else:\n","    #     model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n","\n","    if (\n","        os.path.exists(training_args.output_dir)\n","        and os.listdir(training_args.output_dir)\n","        and training_args.do_train\n","        and not training_args.overwrite_output_dir\n","    ):\n","        raise ValueError(\n","            f\"Output directory ({training_args.output_dir}) already exists and is not empty. Use --overwrite_output_dir to overcome.\"\n","        )\n","\n","    # Setup logging\n","    logging.basicConfig(\n","        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n","        datefmt=\"%m/%d/%Y %H:%M:%S\",\n","        level=logging.INFO if training_args.local_rank in [-1, 0] else logging.WARN,\n","    )\n","    logger.warning(\n","        \"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\",\n","        training_args.local_rank,\n","        training_args.device,\n","        training_args.n_gpu,\n","        bool(training_args.local_rank != -1),\n","        training_args.fp16,\n","    )\n","    logger.info(\"Training/evaluation parameters %s\", training_args)\n","\n","    # Set seed\n","    set_seed(training_args.seed)\n","\n","    # Prepare CONLL-2003 task\n","    labels = get_labels(data_args.labels)\n","    label_map: Dict[int, str] = {i: label for i, label in enumerate(labels)}\n","    num_labels = len(labels)\n","\n","    # Load pretrained model and tokenizer\n","    #\n","    # Distributed training:\n","    # The .from_pretrained methods guarantee that only one local process can concurrently\n","    # download model & vocab.\n","\n","    config = AutoConfig.from_pretrained(\n","        model_args.config_name if model_args.config_name else model_args.model_name_or_path,\n","        num_labels=num_labels,\n","        id2label=label_map,\n","        label2id={label: i for i, label in enumerate(labels)},\n","        cache_dir=model_args.cache_dir,\n","    )\n","    tokenizer = AutoTokenizer.from_pretrained(\n","        model_args.tokenizer_name if model_args.tokenizer_name else model_args.model_name_or_path,\n","        cache_dir=model_args.cache_dir,\n","        use_fast=model_args.use_fast,\n","    )\n","    model = AutoModelForTokenClassification.from_pretrained(\n","        model_args.model_name_or_path,\n","        from_tf=bool(\".ckpt\" in model_args.model_name_or_path),\n","        config=config,\n","        cache_dir=model_args.cache_dir,\n","    )\n","\n","    model_to_save = AutoModel.from_pretrained(\n","        model_args.model_name_or_path,\n","        from_tf=bool(\".ckpt\" in model_args.model_name_or_path),\n","        config=config,\n","        cache_dir=model_args.cache_dir,\n","    )\n","    model_to_save.save_pretrained(training_args.output_dir)\n","    tokenizer.save_pretrained(training_args.output_dir)\n","    # import pdb; pdb.set_trace()\n","\n","\n","    # Get datasets\n","    train_dataset = (\n","        NerDataset(\n","            data_dir=data_args.data_dir,\n","            tokenizer=tokenizer,\n","            labels=labels,\n","            model_type=config.model_type,\n","            max_seq_length=data_args.max_seq_length,\n","            overwrite_cache=data_args.overwrite_cache,\n","            mode=Split.train,\n","        )\n","        if training_args.do_train\n","        else None\n","    )\n","    eval_dataset = (\n","        NerDataset(\n","            data_dir=data_args.data_dir,\n","            tokenizer=tokenizer,\n","            labels=labels,\n","            model_type=config.model_type,\n","            max_seq_length=data_args.max_seq_length,\n","            overwrite_cache=data_args.overwrite_cache,\n","            mode=Split.dev,\n","        )\n","        if training_args.do_eval\n","        else None\n","    )\n","\n","    def align_predictions(predictions: np.ndarray, label_ids: np.ndarray) -> Tuple[List[int], List[int]]:\n","        preds = np.argmax(predictions, axis=2)\n","\n","        batch_size, seq_len = preds.shape\n","\n","        out_label_list = [[] for _ in range(batch_size)]\n","        preds_list = [[] for _ in range(batch_size)]\n","        \n","        for i in range(batch_size):\n","            for j in range(seq_len):\n","                if label_ids[i, j] != nn.CrossEntropyLoss().ignore_index:\n","                    out_label_list[i].append(label_map[label_ids[i][j]])\n","                    preds_list[i].append(label_map[preds[i][j]])\n","\n","        return preds_list, out_label_list\n","\n","    def compute_metrics(p: EvalPrediction) -> Dict:\n","        preds_list, out_label_list = align_predictions(p.predictions, p.label_ids)\n","        \n","        return {\n","            \"precision\": precision_score(out_label_list, preds_list),\n","            \"recall\": recall_score(out_label_list, preds_list),\n","            \"f1\": f1_score(out_label_list, preds_list),\n","        }\n","\n","    # Initialize our Trainer\n","    trainer = Trainer(\n","        model=model,\n","        args=training_args,\n","        train_dataset=train_dataset,\n","        eval_dataset=eval_dataset,\n","        compute_metrics=compute_metrics,\n","    )\n","\n","    # Training\n","    if training_args.do_train:\n","        trainer.train(\n","            model_path=model_args.model_name_or_path if os.path.isdir(model_args.model_name_or_path) else None\n","        )\n","        trainer.save_model()\n","        # For convenience, we also re-save the tokenizer to the same directory,\n","        # so that you can share your model easily on huggingface.co/models =)\n","        if trainer.is_world_process_zero():\n","            tokenizer.save_pretrained(training_args.output_dir)\n","\n","    # Evaluation\n","    results = {}\n","    if training_args.do_eval:\n","        logger.info(\"*** Evaluate ***\")\n","\n","        result = trainer.evaluate()\n","        \n","        output_eval_file = os.path.join(training_args.output_dir, \"eval_results.txt\")\n","        if trainer.is_world_process_zero():\n","            with open(output_eval_file, \"w\") as writer:\n","                logger.info(\"***** Eval results *****\")\n","                for key, value in result.items():\n","                    logger.info(\"  %s = %s\", key, value)\n","                    writer.write(\"%s = %s\\n\" % (key, value))\n","\n","            results.update(result)\n","    \n","    \n","    # Predict\n","    if training_args.do_predict:\n","        test_dataset = NerDataset(\n","            data_dir=data_args.data_dir,\n","            tokenizer=tokenizer,\n","            labels=labels,\n","            model_type=config.model_type,\n","            max_seq_length=data_args.max_seq_length,\n","            overwrite_cache=data_args.overwrite_cache,\n","            mode=Split.test,\n","        )\n","        print('test_dataset:', test_dataset[0])\n","        predictions, label_ids, metrics = trainer.predict(test_dataset)\n","        preds_list, _ = align_predictions(predictions, label_ids)\n","        \n","        # Save predictions\n","        output_test_results_file = os.path.join(training_args.output_dir, \"test_results.txt\")\n","        if trainer.is_world_process_zero():\n","            with open(output_test_results_file, \"w\") as writer:\n","                logger.info(\"***** Test results *****\")\n","                for key, value in metrics.items():\n","                    logger.info(\"  %s = %s\", key, value)\n","                    writer.write(\"%s = %s\\n\" % (key, value))\n","\n","        \n","        output_test_predictions_file = os.path.join(training_args.output_dir, \"test_predictions.txt\")\n","        if trainer.is_world_process_zero():\n","            with open(output_test_predictions_file, \"w\") as writer:\n","                with open(os.path.join(data_args.data_dir, \"test.txt\"), \"r\") as f:\n","                    example_id = 0\n","                    for line in f:\n","                        if line.startswith(\"-DOCSTART-\") or line == \"\" or line == \"\\n\":\n","                            writer.write(line)\n","                            if not preds_list[example_id]:\n","                                example_id += 1\n","                        elif preds_list[example_id]:\n","                            entity_label = preds_list[example_id].pop(0)\n","                            if entity_label == 'O':\n","                                output_line = line.split()[0] + \" \" + entity_label + \"\\n\"\n","                            else:\n","                                output_line = line.split()[0] + \" \" + entity_label[0] + \"\\n\"\n","                            # output_line = line.split()[0] + \" \" + preds_list[example_id].pop(0) + \"\\n\"\n","                            writer.write(output_line)\n","                        else:\n","                            logger.warning(\n","                                \"Maximum sequence length exceeded: No prediction for '%s'.\", line.split()[0]\n","                            )\n","            \n","\n","    return results\n","\n","\n","def _mp_fn(index):\n","    # For xla_spawn (TPUs)\n","    main()\n","\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["11/22/2021 09:58:15 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False\n","11/22/2021 09:58:15 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(\n","_n_gpu=1,\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_pin_memory=True,\n","ddp_find_unused_parameters=None,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","do_eval=True,\n","do_predict=True,\n","do_train=True,\n","eval_accumulation_steps=None,\n","eval_steps=None,\n","evaluation_strategy=IntervalStrategy.NO,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","gradient_accumulation_steps=1,\n","gradient_checkpointing=False,\n","greater_is_better=None,\n","group_by_length=False,\n","hub_model_id=None,\n","hub_strategy=HubStrategy.EVERY_SAVE,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=5e-05,\n","length_column_name=length,\n","load_best_model_at_end=False,\n","local_rank=-1,\n","log_level=-1,\n","log_level_replica=-1,\n","log_on_each_node=True,\n","logging_dir=output_fold_new/output_v4_t5/runs/Nov22_09-58-15_b5b5f6148e18,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=500,\n","logging_strategy=IntervalStrategy.STEPS,\n","lr_scheduler_type=SchedulerType.LINEAR,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=None,\n","mp_parameters=,\n","no_cuda=False,\n","num_train_epochs=8,\n","output_dir=output_fold_new/output_v4_t5,\n","overwrite_output_dir=True,\n","past_index=-1,\n","per_device_eval_batch_size=8,\n","per_device_train_batch_size=32,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","remove_unused_columns=True,\n","report_to=['tensorboard'],\n","resume_from_checkpoint=None,\n","run_name=output_fold_new/output_v4_t5,\n","save_on_each_node=False,\n","save_steps=100,\n","save_strategy=IntervalStrategy.STEPS,\n","save_total_limit=None,\n","seed=1,\n","sharded_ddp=[],\n","skip_memory_metrics=True,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_legacy_prediction_loop=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n","xpu_backend=None,\n",")\n","Some weights of the model checkpoint at dmis-lab/biobert-base-cased-v1.1 were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of the model checkpoint at dmis-lab/biobert-base-cased-v1.1 were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","11/22/2021 09:58:34 - INFO - utils_ner -   Creating features from dataset file at /content/drive/My Drive/biobert/named-entity-recognition/datasets_fold_new/v4_t5/\n","11/22/2021 09:58:35 - INFO - utils_ner -   Writing example 0 of 1934\n","11/22/2021 09:58:35 - INFO - utils_ner -   *** Example ***\n","11/22/2021 09:58:35 - INFO - utils_ner -   guid: train_dev-1\n","11/22/2021 09:58:35 - INFO - utils_ner -   tokens: [CLS] an ##op ##hel ##es step ##hen ##si do ##x - a ##2 shares common ancestry with genes from distant groups of e ##uka ##ryo ##tes encoding a 26 ##s pro ##te ##as ##ome subunit and is in a conserved gene cluster . [SEP]\n","11/22/2021 09:58:35 - INFO - utils_ner -   input_ids: 101 1126 4184 18809 1279 2585 10436 5053 1202 1775 118 170 1477 6117 1887 11626 1114 9077 1121 6531 2114 1104 174 12658 26503 3052 18922 170 1744 1116 5250 1566 2225 6758 27555 1105 1110 1107 170 21996 5565 10005 119 102 0 0 0 0 0 0\n","11/22/2021 09:58:35 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0\n","11/22/2021 09:58:35 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/22/2021 09:58:35 - INFO - utils_ner -   label_ids: -100 2 -100 -100 -100 2 -100 -100 0 -100 -100 -100 -100 2 2 2 2 2 2 2 2 2 2 -100 -100 -100 2 2 2 -100 2 -100 -100 -100 2 2 2 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100\n","11/22/2021 09:58:35 - INFO - utils_ner -   *** Example ***\n","11/22/2021 09:58:35 - INFO - utils_ner -   guid: train_dev-2\n","11/22/2021 09:58:35 - INFO - utils_ner -   tokens: [CLS] the sequence of a clone ##d an ##op ##hel ##es step ##hen ##si gene showed 72 % in ##ferred amino acid identity with d ##ros ##op ##hil ##a me ##lan ##oga ##ster do ##x - a ##2 and 93 % with its put ##ative or ##th ##olo ##g [SEP]\n","11/22/2021 09:58:35 - INFO - utils_ner -   input_ids: 101 1103 4954 1104 170 22121 1181 1126 4184 18809 1279 2585 10436 5053 5565 2799 5117 110 1107 26025 13736 5190 4193 1114 173 5864 4184 20473 1161 1143 4371 23282 4648 1202 1775 118 170 1477 1105 5429 110 1114 1157 1508 5838 1137 1582 12805 1403 102\n","11/22/2021 09:58:35 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","11/22/2021 09:58:35 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/22/2021 09:58:35 - INFO - utils_ner -   label_ids: -100 2 2 2 2 2 -100 2 -100 -100 -100 2 -100 -100 2 2 2 2 2 -100 2 2 2 2 2 -100 -100 -100 -100 2 -100 -100 -100 0 -100 -100 -100 -100 2 2 2 2 2 2 -100 2 -100 -100 -100 -100\n","11/22/2021 09:58:35 - INFO - utils_ner -   *** Example ***\n","11/22/2021 09:58:35 - INFO - utils_ner -   guid: train_dev-3\n","11/22/2021 09:58:35 - INFO - utils_ner -   tokens: [CLS] in an ##op ##hel ##es g ##am ##bia ##e . [SEP]\n","11/22/2021 09:58:35 - INFO - utils_ner -   input_ids: 101 1107 1126 4184 18809 1279 176 2312 10242 1162 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/22/2021 09:58:35 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/22/2021 09:58:35 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/22/2021 09:58:35 - INFO - utils_ner -   label_ids: -100 2 2 -100 -100 -100 2 -100 -100 -100 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n","11/22/2021 09:58:35 - INFO - utils_ner -   *** Example ***\n","11/22/2021 09:58:35 - INFO - utils_ner -   guid: train_dev-4\n","11/22/2021 09:58:35 - INFO - utils_ner -   tokens: [CLS] do ##x - a ##2 is the reported but here ##in disputed structural lo ##cus for dip ##hen ##ol o ##xi ##das ##e a ##2 . [SEP]\n","11/22/2021 09:58:35 - INFO - utils_ner -   input_ids: 101 1202 1775 118 170 1477 1110 1103 2103 1133 1303 1394 11807 8649 25338 6697 1111 20866 10436 4063 184 8745 9028 1162 170 1477 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/22/2021 09:58:35 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/22/2021 09:58:35 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/22/2021 09:58:35 - INFO - utils_ner -   label_ids: -100 0 -100 -100 -100 -100 2 2 2 2 2 -100 2 2 2 -100 2 0 -100 -100 1 -100 -100 -100 1 -100 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n","11/22/2021 09:58:35 - INFO - utils_ner -   *** Example ***\n","11/22/2021 09:58:35 - INFO - utils_ner -   guid: train_dev-5\n","11/22/2021 09:58:35 - INFO - utils_ner -   tokens: [CLS] database searches identified do ##x - a ##2 related gene sequences from 15 non - insect species from diverse groups . [SEP]\n","11/22/2021 09:58:35 - INFO - utils_ner -   input_ids: 101 8539 18806 3626 1202 1775 118 170 1477 2272 5565 10028 1121 1405 1664 118 15754 1530 1121 7188 2114 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/22/2021 09:58:35 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/22/2021 09:58:35 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/22/2021 09:58:35 - INFO - utils_ner -   label_ids: -100 2 2 2 0 -100 -100 -100 -100 2 2 2 2 2 2 -100 -100 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n","11/22/2021 09:58:39 - INFO - utils_ner -   Saving features into cached file /content/drive/My Drive/biobert/named-entity-recognition/datasets_fold_new/v4_t5/cached_train_dev_BertTokenizer_50\n","11/22/2021 09:58:39 - INFO - utils_ner -   Creating features from dataset file at /content/drive/My Drive/biobert/named-entity-recognition/datasets_fold_new/v4_t5/\n","11/22/2021 09:58:39 - INFO - utils_ner -   Writing example 0 of 247\n","11/22/2021 09:58:39 - INFO - utils_ner -   *** Example ***\n","11/22/2021 09:58:39 - INFO - utils_ner -   guid: devel-1\n","11/22/2021 09:58:39 - INFO - utils_ner -   tokens: [CLS] character ##isation , analysis of expression and local ##isation of the op ##sin gene repertoire from the perspective of photo ##per ##io ##dis ##m in the a ##phi ##d a ##cy ##rth ##os ##ip ##hon p ##is ##um . [SEP]\n","11/22/2021 09:58:39 - INFO - utils_ner -   input_ids: 101 1959 5771 117 3622 1104 2838 1105 1469 5771 1104 1103 11769 10606 5565 14674 1121 1103 7281 1104 6307 3365 2660 10396 1306 1107 1103 170 27008 1181 170 3457 11687 2155 9717 8613 185 1548 1818 119 102 0 0 0 0 0 0 0 0 0\n","11/22/2021 09:58:39 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0\n","11/22/2021 09:58:39 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/22/2021 09:58:39 - INFO - utils_ner -   label_ids: -100 2 -100 2 2 2 2 2 2 -100 2 2 0 -100 2 2 2 2 2 2 2 -100 -100 -100 -100 2 2 2 -100 -100 2 -100 -100 -100 -100 -100 2 -100 -100 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n","11/22/2021 09:58:39 - INFO - utils_ner -   *** Example ***\n","11/22/2021 09:58:39 - INFO - utils_ner -   guid: devel-2\n","11/22/2021 09:58:39 - INFO - utils_ner -   tokens: [CLS] organisms exhibit a wide range of seasonal responses as adapt ##ions to predictable annual changes in their environment . [SEP]\n","11/22/2021 09:58:39 - INFO - utils_ner -   input_ids: 101 12023 8245 170 2043 2079 1104 13286 11317 1112 16677 5266 1106 24017 2683 2607 1107 1147 3750 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/22/2021 09:58:39 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/22/2021 09:58:39 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/22/2021 09:58:39 - INFO - utils_ner -   label_ids: -100 2 2 2 2 2 2 2 2 2 2 -100 2 2 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n","11/22/2021 09:58:39 - INFO - utils_ner -   *** Example ***\n","11/22/2021 09:58:39 - INFO - utils_ner -   guid: devel-3\n","11/22/2021 09:58:39 - INFO - utils_ner -   tokens: [CLS] these changes are originally caused by the effect of the earth s cycles around the sun and its a ##xial tilt . [SEP]\n","11/22/2021 09:58:39 - INFO - utils_ner -   input_ids: 101 1292 2607 1132 2034 2416 1118 1103 2629 1104 1103 4033 188 13874 1213 1103 3336 1105 1157 170 27361 20827 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/22/2021 09:58:39 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/22/2021 09:58:39 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/22/2021 09:58:39 - INFO - utils_ner -   label_ids: -100 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n","11/22/2021 09:58:39 - INFO - utils_ner -   *** Example ***\n","11/22/2021 09:58:39 - INFO - utils_ner -   guid: devel-4\n","11/22/2021 09:58:39 - INFO - utils_ner -   tokens: [CLS] examples of seasonal responses include flora ##tion , migration , reproduction and di ##apa ##use . [SEP]\n","11/22/2021 09:58:39 - INFO - utils_ner -   input_ids: 101 5136 1104 13286 11317 1511 16812 2116 117 10348 117 16600 1105 4267 26519 5613 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/22/2021 09:58:39 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/22/2021 09:58:39 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/22/2021 09:58:39 - INFO - utils_ner -   label_ids: -100 2 2 2 2 2 2 -100 2 2 2 2 2 2 -100 -100 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n","11/22/2021 09:58:39 - INFO - utils_ner -   *** Example ***\n","11/22/2021 09:58:39 - INFO - utils_ner -   guid: devel-5\n","11/22/2021 09:58:39 - INFO - utils_ner -   tokens: [CLS] in temperate climate zones , the most robust variable to predict seasons is the length of the day ( i . e . the photo ##per ##io ##d ) . [SEP]\n","11/22/2021 09:58:39 - INFO - utils_ner -   input_ids: 101 1107 18606 4530 10490 117 1103 1211 17351 7898 1106 17163 2955 1110 1103 2251 1104 1103 1285 113 178 119 174 119 1103 6307 3365 2660 1181 114 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/22/2021 09:58:39 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/22/2021 09:58:39 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/22/2021 09:58:39 - INFO - utils_ner -   label_ids: -100 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 -100 2 2 2 -100 -100 -100 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n","11/22/2021 09:58:40 - INFO - utils_ner -   Saving features into cached file /content/drive/My Drive/biobert/named-entity-recognition/datasets_fold_new/v4_t5/cached_devel_BertTokenizer_50\n","/usr/local/lib/python3.7/dist-packages/transformers/trainer.py:1054: FutureWarning: `model_path` is deprecated and will be removed in a future version. Use `resume_from_checkpoint` instead.\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 1934\n","  Num Epochs = 8\n","  Instantaneous batch size per device = 32\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 488\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='488' max='488' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [488/488 05:04, Epoch 8/8]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to output_fold_new/output_v4_t5/checkpoint-100\n","Configuration saved in output_fold_new/output_v4_t5/checkpoint-100/config.json\n","Model weights saved in output_fold_new/output_v4_t5/checkpoint-100/pytorch_model.bin\n","Saving model checkpoint to output_fold_new/output_v4_t5/checkpoint-200\n","Configuration saved in output_fold_new/output_v4_t5/checkpoint-200/config.json\n","Model weights saved in output_fold_new/output_v4_t5/checkpoint-200/pytorch_model.bin\n","Saving model checkpoint to output_fold_new/output_v4_t5/checkpoint-300\n","Configuration saved in output_fold_new/output_v4_t5/checkpoint-300/config.json\n","Model weights saved in output_fold_new/output_v4_t5/checkpoint-300/pytorch_model.bin\n","Saving model checkpoint to output_fold_new/output_v4_t5/checkpoint-400\n","Configuration saved in output_fold_new/output_v4_t5/checkpoint-400/config.json\n","Model weights saved in output_fold_new/output_v4_t5/checkpoint-400/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Saving model checkpoint to output_fold_new/output_v4_t5\n","Configuration saved in output_fold_new/output_v4_t5/config.json\n","Model weights saved in output_fold_new/output_v4_t5/pytorch_model.bin\n","tokenizer config file saved in output_fold_new/output_v4_t5/tokenizer_config.json\n","Special tokens file saved in output_fold_new/output_v4_t5/special_tokens_map.json\n","11/22/2021 10:03:52 - INFO - __main__ -   *** Evaluate ***\n","***** Running Evaluation *****\n","  Num examples = 247\n","  Batch size = 8\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='61' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [31/31 00:06]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["11/22/2021 10:03:55 - INFO - __main__ -   ***** Eval results *****\n","11/22/2021 10:03:55 - INFO - __main__ -     eval_loss = 0.09761184453964233\n","11/22/2021 10:03:55 - INFO - __main__ -     eval_precision = 0.8118466898954704\n","11/22/2021 10:03:55 - INFO - __main__ -     eval_recall = 0.8566176470588235\n","11/22/2021 10:03:55 - INFO - __main__ -     eval_f1 = 0.8336314847942754\n","11/22/2021 10:03:55 - INFO - __main__ -     eval_runtime = 2.9529\n","11/22/2021 10:03:55 - INFO - __main__ -     eval_samples_per_second = 83.645\n","11/22/2021 10:03:55 - INFO - __main__ -     eval_steps_per_second = 10.498\n","11/22/2021 10:03:55 - INFO - __main__ -     epoch = 8.0\n","11/22/2021 10:03:55 - INFO - utils_ner -   Creating features from dataset file at /content/drive/My Drive/biobert/named-entity-recognition/datasets_fold_new/v4_t5/\n","11/22/2021 10:03:56 - INFO - utils_ner -   Writing example 0 of 238\n","11/22/2021 10:03:56 - INFO - utils_ner -   *** Example ***\n","11/22/2021 10:03:56 - INFO - utils_ner -   guid: test-1\n","11/22/2021 10:03:56 - INFO - utils_ner -   tokens: [CLS] g ##11 ##9 ##s ace - 1 mutation con ##fer ##ring insect ##icide resistance detected in the cu ##lex p ##ip ##iens complex in m ##oro ##cco . [SEP]\n","11/22/2021 10:03:56 - INFO - utils_ner -   input_ids: 101 176 14541 1580 1116 20839 118 122 17895 14255 6732 3384 15754 24421 4789 11168 1107 1103 16408 21729 185 9717 23461 2703 1107 182 14824 14566 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/22/2021 10:03:56 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/22/2021 10:03:56 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/22/2021 10:03:56 - INFO - utils_ner -   label_ids: -100 2 -100 -100 -100 0 -100 -100 2 2 -100 -100 2 -100 2 2 2 2 2 -100 2 -100 -100 2 2 2 -100 -100 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n","11/22/2021 10:03:56 - INFO - utils_ner -   *** Example ***\n","11/22/2021 10:03:56 - INFO - utils_ner -   guid: test-2\n","11/22/2021 10:03:56 - INFO - utils_ner -   tokens: [CLS] background : a ##rb ##ov ##ir ##uses are controlled through insect ##icide control of their m ##os ##quito vector . [SEP]\n","11/22/2021 10:03:56 - INFO - utils_ner -   input_ids: 101 3582 131 170 26281 3292 3161 14225 1132 4013 1194 15754 24421 1654 1104 1147 182 2155 21594 9479 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/22/2021 10:03:56 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/22/2021 10:03:56 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/22/2021 10:03:56 - INFO - utils_ner -   label_ids: -100 2 2 2 -100 -100 -100 -100 2 2 2 2 -100 2 2 2 2 -100 -100 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n","11/22/2021 10:03:56 - INFO - utils_ner -   *** Example ***\n","11/22/2021 10:03:56 - INFO - utils_ner -   guid: test-3\n","11/22/2021 10:03:56 - INFO - utils_ner -   tokens: [CLS] however , in ##con ##side ##rate use of insect ##icides often results in the selection of resistance in treated populations , so that monitoring is required to op ##ti ##mize their usage . [SEP]\n","11/22/2021 10:03:56 - INFO - utils_ner -   input_ids: 101 1649 117 1107 7235 5570 5498 1329 1104 15754 25606 1510 2686 1107 1103 4557 1104 4789 1107 5165 6623 117 1177 1115 9437 1110 2320 1106 11769 3121 19092 1147 7991 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/22/2021 10:03:56 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/22/2021 10:03:56 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/22/2021 10:03:56 - INFO - utils_ner -   label_ids: -100 2 2 2 -100 -100 -100 2 2 2 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 -100 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n","11/22/2021 10:03:56 - INFO - utils_ner -   *** Example ***\n","11/22/2021 10:03:56 - INFO - utils_ner -   guid: test-4\n","11/22/2021 10:03:56 - INFO - utils_ner -   tokens: [CLS] here , cu ##lex p ##ip ##iens ( west ni ##le and rift valley fever virus vector ) specimens were collected from four m ##oro ##cca ##n cities . [SEP]\n","11/22/2021 10:03:56 - INFO - utils_ner -   input_ids: 101 1303 117 16408 21729 185 9717 23461 113 1745 11437 1513 1105 25414 4524 10880 7942 9479 114 9985 1127 4465 1121 1300 182 14824 19495 1179 3038 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/22/2021 10:03:56 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/22/2021 10:03:56 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/22/2021 10:03:56 - INFO - utils_ner -   label_ids: -100 2 2 2 -100 2 -100 -100 2 2 2 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 -100 -100 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n","11/22/2021 10:03:56 - INFO - utils_ner -   *** Example ***\n","11/22/2021 10:03:56 - INFO - utils_ner -   guid: test-5\n","11/22/2021 10:03:56 - INFO - utils_ner -   tokens: [CLS] levels of su ##s ##ce ##pt ##ibility to the organ ##op ##hos ##phate ( op ) insect ##icide ma ##lat ##hi ##on were assessed using world health organization ( who ) - recommended bio ##ass ##ays . [SEP]\n","11/22/2021 10:03:56 - INFO - utils_ner -   input_ids: 101 3001 1104 28117 1116 2093 6451 7706 1106 1103 5677 4184 15342 26290 113 11769 114 15754 24421 12477 16236 3031 1320 1127 14758 1606 1362 2332 2369 113 1150 114 118 6315 25128 11192 22979 119 102 0 0 0 0 0 0 0 0 0 0 0\n","11/22/2021 10:03:56 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n","11/22/2021 10:03:56 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/22/2021 10:03:56 - INFO - utils_ner -   label_ids: -100 2 2 2 -100 -100 -100 -100 2 2 2 -100 -100 -100 2 2 2 2 -100 2 -100 -100 -100 2 2 2 2 2 2 2 2 2 2 -100 2 -100 -100 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n","11/22/2021 10:03:56 - INFO - utils_ner -   Saving features into cached file /content/drive/My Drive/biobert/named-entity-recognition/datasets_fold_new/v4_t5/cached_test_BertTokenizer_50\n","***** Running Prediction *****\n","  Num examples = 238\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["test_dataset: InputFeatures(input_ids=[101, 176, 14541, 1580, 1116, 20839, 118, 122, 17895, 14255, 6732, 3384, 15754, 24421, 4789, 11168, 1107, 1103, 16408, 21729, 185, 9717, 23461, 2703, 1107, 182, 14824, 14566, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label_ids=[-100, 2, -100, -100, -100, 0, -100, -100, 2, 2, -100, -100, 2, -100, 2, 2, 2, 2, 2, -100, 2, -100, -100, 2, 2, 2, -100, -100, 2, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100])\n"]},{"output_type":"stream","name":"stderr","text":["11/22/2021 10:04:00 - INFO - __main__ -   ***** Test results *****\n","11/22/2021 10:04:00 - INFO - __main__ -     test_loss = 0.052847206592559814\n","11/22/2021 10:04:00 - INFO - __main__ -     test_precision = 0.824\n","11/22/2021 10:04:00 - INFO - __main__ -     test_recall = 0.9809523809523809\n","11/22/2021 10:04:00 - INFO - __main__ -     test_f1 = 0.8956521739130435\n","11/22/2021 10:04:00 - INFO - __main__ -     test_runtime = 2.7497\n","11/22/2021 10:04:00 - INFO - __main__ -     test_samples_per_second = 86.556\n","11/22/2021 10:04:00 - INFO - __main__ -     test_steps_per_second = 10.91\n"]}]}]}